{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cnn_result_ modified_0607.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDchbH2CoYX4","executionInfo":{"status":"ok","timestamp":1623231925265,"user_tz":-540,"elapsed":369,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}},"outputId":"eab5c913-eabc-4cb1-ffe5-e511668bf849"},"source":["%cd '/gdrive/MyDrive/2021-1-Mentor(CNN)/2021-1-Classification_4classes/code'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/gdrive/MyDrive/2021-1-Mentor(CNN)/2021-1-Classification_4classes/code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJf1emux9Ooa","executionInfo":{"status":"ok","timestamp":1623231932041,"user_tz":-540,"elapsed":6407,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["import os, math, time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","\n","# seed for reproducibility\n","import random \n","import tensorflow as tf\n","from keras import backend as K\n","seed_value=101;\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","np.random.seed(seed_value)\n","random.seed(seed_value)\n","tf.random.set_seed(seed_value)\n","\n","\n","import keras\n","from keras import models, layers\n","from tensorflow.keras.callbacks import Callback\n","from IPython.display import clear_output\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics\n","\n","from sklearn.utils import class_weight\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIgAeb4Y9Ood","executionInfo":{"status":"ok","timestamp":1623231932042,"user_tz":-540,"elapsed":8,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["# parameters\n","NUM_TARGET_LABELS = 4\n","\n","file_path = './'\n","\n","fname_image = '../data/data_image.npy'\n","fname_labels = '../data/labels.npy'\n","label_names = ['com','cod','ca','st','ua','au','cy','br','others']\n","\n","exp_name = 'ResNet152_origin'\n","result_path = f'../result/{exp_name}'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGulR7fDSAv_","executionInfo":{"status":"ok","timestamp":1623231932410,"user_tz":-540,"elapsed":4,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["######################## IF WINDOWS,\n","gpu = tf.config.experimental.list_physical_devices('GPU')\n","try:\n","    tf.config.experimental.set_memory_growth(gpu[0], True) \n","except RuntimeError as e:\n","    print(e) "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"yujVv3w9iFEv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623231932410,"user_tz":-540,"elapsed":3,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}},"outputId":"6b6f05f5-f1b3-4ccd-c1ca-027acf90a9ae"},"source":["####################################################\n","#######  EXECUTE ONLY IF USING GOOGLE COLAB ########\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","file_path = '/gdrive/MyDrive/2021-1-Mentor(CNN)/2021-1-Classification_4classes/code'\n","name_image = os.path.join(file_path, fname_image)\n","name_labels = os.path.join(file_path, fname_labels)\n","####################################################"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Xk-Ui0P9Oog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623231955112,"user_tz":-540,"elapsed":22704,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}},"outputId":"62aa7ae5-d5c8-4147-fdea-81ac68659078"},"source":["### set data and labels\n","# load data and labels\n","data = np.load(fname_image)\n","labels = np.load(fname_labels)\n","\n","# set unique labels\n","label_unique = np.array([list(x) for x in set(tuple(x) for x in labels)])\n","label_unique_indices = np.array([list(np.where((labels == val).all(axis=1)))[0] for val in label_unique])\n","label_unique_counts = np.array([len(x) for x in label_unique_indices])\n","\n","# sort by frequency\n","temp_ind = label_unique_counts.argsort()[::-1]\n","label_class_info = label_unique[temp_ind]\n","label_class_indices = label_unique_indices[temp_ind]\n","label_class_counts = label_unique_counts[temp_ind]\n","\n","# final label and info\n","label_final = labels[:,0]\n","for label_i in range(len(label_unique_counts)):\n","    label_final[label_class_indices[label_i]] = label_i\n","\n","label_info = [label_class_info[x.astype(int)] for x in label_final]\n","\n","\n","# cut data and labels\n","target_ind = np.array(label_final) >= NUM_TARGET_LABELS\n","label_other = np.array(label_final)[target_ind]\n","data_other = data[target_ind] / 255.0\n","\n","target_ind = np.array(label_final) < NUM_TARGET_LABELS\n","label_final = np.array(label_final)[target_ind]\n","data_final = data[target_ind] / 255.0\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AsLrREqBlXZO","executionInfo":{"status":"ok","timestamp":1623231955494,"user_tz":-540,"elapsed":384,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["### model and function definition\n","\n","\n","\n","# model class\n","class Network():\n","  start_time = 0\n","\n","  num_output_label = 4\n","\n","  def __init__(self, num_output_label=4):\n","    self.num_output_label = num_output_label\n","\n","  def create(self):\n","    self.model = models.Sequential()\n","    self.model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(160, 160, 3)))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Flatten())\n","    self.model.add(layers.Dense(256, activation='relu'))\n","    self.model.add(layers.Dropout(0.3))\n","\n","    self.model.add(layers.Dense(self.num_output_label, activation='softmax'))\n","\n","    self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","\n","#    def create(self):\n","#        self.model=tf.keras.application.ResNet152(\n","#            weights='imagenet', include_top=False, input_shape=(160, 160, 3)\n","#        )\n","\n","\n","# training history callback class\n","class TrainingHistoryCallback(Callback):\n","\n","  def __init__(self, fold_i, x_test, y_test, save_path, visualize=True):\n","    self.fold_i = fold_i\n","    self.x_test = x_test\n","    self.y_test = y_test\n","    self.save_path = save_path\n","    self.visualize = visualize\n","\n","  def on_train_begin(self, logs={}):\n","    self.update_freq = 10\n","    self.curr_epoch = 0\n","    self.x = []\n","\n","    self.train_loss = []\n","    self.train_acc = []\n","    self.val_loss = []\n","    self.val_acc = []\n","\n","    self.fig = plt.figure()\n","\n","    self.logs = []\n","    self.y_pred = []\n","\n","    self.best_val_loss = 1000000\n","    self.best_acc = 0\n","    self.best_f1 = 0\n","    \n","    self.best_val_loss_epoch = None\n","    self.best_acc_epoch = None\n","    self.best_f1_epoch = None\n","    \n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    self.curr_epoch += 1\n","    self.x.append(self.curr_epoch)\n","    self.train_loss.append(logs.get('loss'))\n","    self.train_acc.append(logs.get('accuracy'))\n","    self.val_loss.append(logs.get('val_loss'))\n","    self.val_acc.append(logs.get('val_accuracy'))\n","    self.logs.append(logs)\n","    self.y_pred.append(self.model.predict(self.x_test))\n","\n","    # check whether model has the best validation loss\n","    if logs.get('val_loss') < self.best_val_loss:\n","      self.best_val_loss = logs.get('val_loss')\n","      self.best_val_loss_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_loss.hdf5'),overwrite=True)\n","        \n","    # check whether model has the best validation accuracy\n","    if logs.get('val_accuracy') > self.best_acc:\n","      self.best_acc = logs.get('val_accuracy')\n","      self.best_acc_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_acc.hdf5'),overwrite=True)\n","    \n","    # check whether model has the best mean f1 score\n","    _, _, fscore, _ = metrics.precision_recall_fscore_support(np.argmax(self.y_test, axis=1),\n","                                                              np.argmax(self.model.predict(self.x_test),axis=1))\n","    if np.mean(fscore) > self.best_f1:\n","      self.best_f1 = np.mean(fscore)\n","      self.best_f1_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_f1.hdf5'),overwrite=True)\n","        \n","    # visualization\n","    if (self.visualize and self.curr_epoch % self.update_freq == 0):\n","      clear_output(wait=True)\n","\n","      plt.figure(figsize=(12,5))\n","      plt.subplot(121)\n","      plt.plot(self.x[5:], self.train_loss[5:], label=\"train_loss\")\n","      plt.plot(self.x[5:], self.val_loss[5:], label=\"val_loss\")\n","      plt.legend()\n","\n","      plt.subplot(122)\n","      plt.plot(self.x, self.train_acc, label=\"train_acc\")\n","      plt.plot(self.x, self.val_acc, label=\"val_acc\")\n","      plt.legend()\n","      plt.show()\n","\n","      print(\"fold = \",self.fold_i, \"epoch =\",self.curr_epoch)\n","      print(\"\\ttrain_loss = \", self.train_loss[-1], \", val_loss = \", self.val_loss[-1])\n","      print(\"\\t\\ttrain_acc = \", self.train_acc[-1], \", val_acc = \", self.val_acc[-1])\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaYK8G6IThEe","executionInfo":{"status":"ok","timestamp":1623231969460,"user_tz":-540,"elapsed":13968,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import resnet\n","from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\n","from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n","from tensorflow.keras.models import Model\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","\n","from tensorflow.keras.applications import ResNet152\n","# 모델 불러오기\n","conv_layers = ResNet152(weights='imagenet', include_top=False, input_shape=(160, 160, 3), pooling='max')\n","#conv_layers.summary()\n","\n","# Convolution Layer를 학습되지 않도록 고정 \n","#for layer in conv_layers.layers:\n","#    layer.trainable = False\n","\n","# 새로운 모델 생성하기\n","model = models.Sequential()\n","\n","# VGG16모델의 Convolution Layer를 추가\n","model.add(conv_layers)\n"," \n","# 모델의 Fully Connected 부분을 재구성\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(4, activation='softmax'))\n","\n","#model.summary() -> built first?"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":612},"id":"uKE28mj4UAKi","executionInfo":{"status":"error","timestamp":1623232006332,"user_tz":-540,"elapsed":36874,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}},"outputId":"59f4b8ee-9d02-475e-ef46-ed96204d3306"},"source":["#0609 keras.utils.to_categorical 에러\n","#AttributeError: module 'keras.utils' has no attribute 'to_categorical'\n","\n","from tensorflow import keras\n","\n","### train and evaluate model\n","# one-hot encoding\n","label_final_onehot = keras.utils.to_categorical(label_final)\n","\n","# kfold\n","kfold_divider = StratifiedKFold(n_splits = 10, shuffle=True)\n","\n","# initialize\n","os.mkdir(os.path.join(result_path))\n","\n","\n","# main\n","for fold_i, (ind_train,ind_test) in enumerate(kfold_divider.split(data_final, label_final)):\n","  # set path to save\n","  result_path_current = f'{result_path}/{fold_i+1}'\n","  os.mkdir(os.path.join(file_path,result_path_current))\n","\n","  # shuffle\n","  x_train, x_test = data_final[ind_train], data_final[ind_test]\n","  y_train, y_test = label_final_onehot[ind_train], label_final_onehot[ind_test]\n","\n","\n","\n","  # data augmentation\n","  data_generator = ImageDataGenerator(rotation_range=90,  \n","                                      zoom_range=[0.5,1.0],\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      width_shift_range=0.2,\n","                                      height_shift_range=0.2,\n","                                      fill_mode='wrap')\n","\n","\n","\n","  # class weighting\n","  label_int = np.argmax(label_final_onehot, axis=1)\n","  class_weights = class_weight.compute_class_weight('balanced',  np.unique(label_int), label_int)\n","  class_weights_dict = dict(enumerate(class_weights))\n","\n","\n","\n","  # training initialization\n","  # network = Network(num_output_label=NUM_TARGET_LABELS)\n","  #network = model\n","  \n","  history_callback = TrainingHistoryCallback(fold_i+1, x_test, y_test, result_path_current, visualize=True)\n","  #checkpoint_callback = keras.callbacks.ModelCheckpoint(os.path.join(result_path_current,'model.hdf5'), verbose=0, save_best_only=True)\n","  earlystop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)\n","\n","  start_time = time.time()\n","\n","  # training\n","  #network.create()\n","  #network.summary()\n","  network = model\n","\n","\n","  batch_size=64\n","  epochs=1000\n","\n","\n","  #모델 컴파일\n","\n","  network.compile(loss='categorical_crossentropy',\n","              optimizer=\"adam\",\n","              metrics=['accuracy'])\n","  #모델학습 \n","  training_history = network.fit(\n","      data_generator.flow(x_train, y_train, batch_size=batch_size),\n","      validation_data=(x_test,y_test),\n","      steps_per_epoch=x_train.shape[0] // batch_size,\n","      epochs=epochs, verbose=1,\n","      class_weight=class_weights_dict, \n","      callbacks = [history_callback, earlystop_callback]    \n","  )\n","  #print(\"elapsed : {}\".format(time.time() - start_time))\n","  \n","  network.summary()\n","\n","  # save result\n","  elapsed_time = np.array(time.time() - start_time)\n","\n","  x_test\n","  x_other = data_other\n","  y_test = np.argmax(y_test, axis=1)\n","  ind_test = np.array(ind_test)\n","\n","  epoch_list = np.array(history_callback.x)\n","  train_loss = np.array(history_callback.train_loss)\n","  train_acc = np.array(history_callback.train_acc)\n","  val_loss = np.array(history_callback.val_loss)\n","  val_acc = np.array(history_callback.val_acc)\n","\n","  pred_history = np.array(history_callback.y_pred)\n","\n","\n","  best_val_loss_epoch = history_callback.best_val_loss_epoch\n","  best_acc_epoch = history_callback.best_acc_epoch\n","  best_f1_epoch = history_callback.best_f1_epoch\n","\n","  np.savez(os.path.join(result_path_current,'mat.npz'),\n","          elapsed_time=elapsed_time,\n","          x_test=x_test, y_test=y_test, ind_test=ind_test,\n","          epoch_list=epoch_list,\n","          train_loss=train_loss, train_acc=train_acc,\n","          val_loss=val_loss, val_acc=val_acc,\n","          pred_history=pred_history,\n","          x_other=x_other,\n","          best_val_loss_epoch=best_val_loss_epoch, best_acc_epoch=best_acc_epoch, best_f1_epoch=best_f1_epoch\n","          )\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/1000\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-42cf3382f61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhistory_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m   )\n\u001b[1;32m     81\u001b[0m   \u001b[0;31m#print(\"elapsed : {}\".format(time.time() - start_time))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[256,1024,10,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/resnet152/conv4_block8_3_conv/Conv2D (defined at <ipython-input-9-42cf3382f61a>:79) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_37681]\n\nFunction call stack:\ntrain_function\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"j1QbRoD4XZDE","executionInfo":{"status":"aborted","timestamp":1623232006332,"user_tz":-540,"elapsed":6,"user":{"displayName":"­이유정(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"05054975951149389911"}}},"source":["### evaluation\n","y_true = np.argmax(y_test, axis=1)\n","y_pred = np.argmax(history_callback.best_model.predict(x_test),axis=1)\n","accuracy = metrics.accuracy_score(y_true,y_pred)\n","precision, sensitivity, fscore, support = metrics.precision_recall_fscore_support(y_true, y_pred)\n","auc1 = metrics.roc_auc_score(y_true, history_callback.best_model.predict(x_test), multi_class='ovo')\n","auc2 = metrics.roc_auc_score(y_true, history_callback.best_model.predict(x_test), multi_class='ovr')\n","conf_mat = confusion_matrix(y_true,y_pred)\n","\n","print(accuracy)\n","print(precision)\n","print(recall)\n","print(fscore)\n","print(support)\n","print(auc1)\n","print(auc2)\n","print(conf_mat)"],"execution_count":null,"outputs":[]}]}