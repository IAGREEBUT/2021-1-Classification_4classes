{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cnn_result_ modified_0607.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"XJf1emux9Ooa"},"source":["import os, math, time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# seed for reproducibility\n","import random \n","import tensorflow as tf\n","from keras import backend as K\n","seed_value=101;\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","np.random.seed(seed_value)\n","random.seed(seed_value)\n","tf.random.set_seed(seed_value)\n","\n","\n","import keras\n","from keras import models, layers\n","from tensorflow.keras.callbacks import Callback\n","from IPython.display import clear_output\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics\n","\n","from sklearn.utils import class_weight\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIgAeb4Y9Ood"},"source":["# parameters\n","NUM_TARGET_LABELS = 5\n","\n","file_path = './'\n","\n","fname_image = '../data/data_image.npy'\n","fname_labels = '../data/labels.npy'\n","label_names = ['com','cod','ca','st','ua','au','cy','br','others']\n","\n","exp_name = 'ResNet152'\n","result_path = f'../result/{exp_name}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGulR7fDSAv_"},"source":["######################## IF WINDOWS,\n","gpu = tf.config.experimental.list_physical_devices('GPU')\n","try:\n","    tf.config.experimental.set_memory_growth(gpu[0], True) \n","except RuntimeError as e:\n","    print(e) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yujVv3w9iFEv"},"source":["####################################################\n","#######  EXECUTE ONLY IF USING GOOGLE COLAB ########\n","#from google.colab import drive\n","#drive.mount('/content/gdrive/')\n","\n","#ile_path = './gdrive/My Drive/kidney_stone/code'\n","#name_image = os.path.join(file_path, fname_image)\n","#name_labels = os.path.join(file_path, fname_labels)\n","####################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Xk-Ui0P9Oog"},"source":["### set data and labels\n","# load data and labels\n","data = np.load(fname_image)\n","labels = np.load(fname_labels)\n","\n","# set unique labels\n","label_unique = np.array([list(x) for x in set(tuple(x) for x in labels)])\n","label_unique_indices = np.array([list(np.where((labels == val).all(axis=1)))[0] for val in label_unique])\n","label_unique_counts = np.array([len(x) for x in label_unique_indices])\n","\n","# sort by frequency\n","temp_ind = label_unique_counts.argsort()[::-1]\n","label_class_info = label_unique[temp_ind]\n","label_class_indices = label_unique_indices[temp_ind]\n","label_class_counts = label_unique_counts[temp_ind]\n","\n","# final label and info\n","label_final = labels[:,0]\n","for label_i in range(len(label_unique_counts)):\n","    label_final[label_class_indices[label_i]] = label_i\n","\n","label_info = [label_class_info[x.astype(int)] for x in label_final]\n","\n","\n","# cut data and labels\n","target_ind = np.array(label_final) >= NUM_TARGET_LABELS\n","label_other = np.array(label_final)[target_ind]\n","data_other = data[target_ind] / 255.0\n","\n","target_ind = np.array(label_final) < NUM_TARGET_LABELS\n","label_final = np.array(label_final)[target_ind]\n","data_final = data[target_ind] / 255.0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsLrREqBlXZO"},"source":["### model and function definition\n","\n","# model class\n","class Network():\n","  start_time = 0\n","\n","  num_output_label = 4\n","\n","  def __init__(self, num_output_label=4):\n","    self.num_output_label = num_output_label\n","\n","  def create(self):\n","    self.model = models.Sequential()\n","    self.model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(160, 160, 3)))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","    self.model.add(layers.MaxPooling2D((2, 2)))\n","    self.model.add(layers.Dropout(0.25))\n","\n","    self.model.add(layers.Flatten())\n","    self.model.add(layers.Dense(256, activation='relu'))\n","    self.model.add(layers.Dropout(0.3))\n","\n","    self.model.add(layers.Dense(self.num_output_label, activation='softmax'))\n","\n","    self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# training history callback class\n","class TrainingHistoryCallback(Callback):\n","\n","  def __init__(self, fold_i, x_test, y_test, save_path, visualize=True):\n","    self.fold_i = fold_i\n","    self.x_test = x_test\n","    self.y_test = y_test\n","    self.save_path = save_path\n","    self.visualize = visualize\n","\n","  def on_train_begin(self, logs={}):\n","    self.update_freq = 10\n","    self.curr_epoch = 0\n","    self.x = []\n","\n","    self.train_loss = []\n","    self.train_acc = []\n","    self.val_loss = []\n","    self.val_acc = []\n","\n","    self.fig = plt.figure()\n","\n","    self.logs = []\n","    self.y_pred = []\n","\n","    self.best_val_loss = 1000000\n","    self.best_acc = 0\n","    self.best_f1 = 0\n","    \n","    self.best_val_loss_epoch = None\n","    self.best_acc_epoch = None\n","    self.best_f1_epoch = None\n","    \n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    self.curr_epoch += 1\n","    self.x.append(self.curr_epoch)\n","    self.train_loss.append(logs.get('loss'))\n","    self.train_acc.append(logs.get('accuracy'))\n","    self.val_loss.append(logs.get('val_loss'))\n","    self.val_acc.append(logs.get('val_accuracy'))\n","    self.logs.append(logs)\n","    self.y_pred.append(self.model.predict(self.x_test))\n","\n","    # check whether model has the best validation loss\n","    if logs.get('val_loss') < self.best_val_loss:\n","      self.best_val_loss = logs.get('val_loss')\n","      self.best_val_loss_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_loss.hdf5'),overwrite=True)\n","        \n","    # check whether model has the best validation accuracy\n","    if logs.get('val_accuracy') > self.best_acc:\n","      self.best_acc = logs.get('val_accuracy')\n","      self.best_acc_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_acc.hdf5'),overwrite=True)\n","    \n","    # check whether model has the best mean f1 score\n","    _, _, fscore, _ = metrics.precision_recall_fscore_support(np.argmax(self.y_test, axis=1),\n","                                                              np.argmax(self.model.predict(self.x_test),axis=1))\n","    if np.mean(fscore) > self.best_f1:\n","      self.best_f1 = np.mean(fscore)\n","      self.best_f1_epoch = self.curr_epoch\n","      self.model.save(os.path.join(self.save_path,'model_best_f1.hdf5'),overwrite=True)\n","        \n","    # visualization\n","    if (self.visualize and self.curr_epoch % self.update_freq == 0):\n","      clear_output(wait=True)\n","\n","      plt.figure(figsize=(12,5))\n","      plt.subplot(121)\n","      plt.plot(self.x[5:], self.train_loss[5:], label=\"train_loss\")\n","      plt.plot(self.x[5:], self.val_loss[5:], label=\"val_loss\")\n","      plt.legend()\n","\n","      plt.subplot(122)\n","      plt.plot(self.x, self.train_acc, label=\"train_acc\")\n","      plt.plot(self.x, self.val_acc, label=\"val_acc\")\n","      plt.legend()\n","      plt.show()\n","\n","      print(\"fold = \",self.fold_i, \"epoch =\",self.curr_epoch)\n","      print(\"\\ttrain_loss = \", self.train_loss[-1], \", val_loss = \", self.val_loss[-1])\n","      print(\"\\t\\ttrain_acc = \", self.train_acc[-1], \", val_acc = \", self.val_acc[-1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaYK8G6IThEe"},"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import vgg16\n","\n","from tensorflow.keras.applications import VGG16\n","# 모델 불러오기\n","conv_layers = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 새로운 모델 생성하기\n","model = models.Sequential()\n","\n","# VGG16모델의 Convolution Layer를 추가\n","model.add(conv_layers)\n"," \n","# 모델의 Fully Connected 부분을 재구성\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(4, activation='softmax'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"uKE28mj4UAKi","outputId":"c81645ac-6a9b-4c5f-c569-86a3be70482b"},"source":["### train and evaluate model\n","# one-hot encoding\n","label_final_onehot = keras.utils.to_categorical(label_final)\n","\n","# kfold\n","kfold_divider = StratifiedKFold(n_splits = 10, shuffle=True)\n","\n","# initialize\n","os.mkdir(os.path.join(result_path))\n","\n","# main\n","for fold_i, (ind_train,ind_test) in enumerate(kfold_divider.split(data_final, label_final)):\n","  # set path to save\n","  result_path_current = f'{result_path}/{fold_i+1}'\n","  os.mkdir(os.path.join(file_path,result_path_current))\n","\n","  # shuffle\n","  x_train, x_test = data_final[ind_train], data_final[ind_test]\n","  y_train, y_test = label_final_onehot[ind_train], label_final_onehot[ind_test]\n","\n","  # data augmentation\n","  data_generator = ImageDataGenerator(rotation_range=90,  \n","                                      zoom_range=[0.5,1.0],\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      width_shift_range=0.2,\n","                                      height_shift_range=0.2,\n","                                      fill_mode='wrap')\n","\n","  # class weighting\n","  label_int = np.argmax(label_final_onehot, axis=1)\n","  class_weights = class_weight.compute_class_weight('balanced',  np.unique(label_int), label_int)\n","  class_weights_dict = dict(enumerate(class_weights))\n","\n","\n","  # training initialization\n","  # network = Network(num_output_label=NUM_TARGET_LABELS)\n","  network = model\n","  \n","  history_callback = TrainingHistoryCallback(fold_i+1, x_test, y_test, result_path_current, visualize=False)\n","  #checkpoint_callback = keras.callbacks.ModelCheckpoint(os.path.join(result_path_current,'model.hdf5'), verbose=0, save_best_only=True)\n","  earlystop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)\n","\n","  start_time = time.time()\n","\n","  # training\n","  network.create()\n","  network.model.summary()\n","\n","  batch_size=256\n","  epochs=1000\n","  training_history = network.model.fit(\n","      data_generator.flow(x_train, y_train, batch_size=batch_size),\n","      validation_data=(x_test,y_test),\n","      steps_per_epoch=x_train.shape[0] // batch_size,\n","      epochs=epochs, verbose=1,\n","      class_weight=class_weights_dict, \n","      callbacks = [history_callback, earlystop_callback]    \n","  )\n","  #print(\"elapsed : {}\".format(time.time() - start_time))\n","  \n","  # save result\n","  elapsed_time = np.array(time.time() - start_time)\n","\n","  x_test\n","  x_other = data_other\n","  y_test = np.argmax(y_test, axis=1)\n","  ind_test = np.array(ind_test)\n","\n","  epoch_list = np.array(history_callback.x)\n","  train_loss = np.array(history_callback.train_loss)\n","  train_acc = np.array(history_callback.train_acc)\n","  val_loss = np.array(history_callback.val_loss)\n","  val_acc = np.array(history_callback.val_acc)\n","\n","  pred_history = np.array(history_callback.y_pred)\n","\n","\n","  best_val_loss_epoch = history_callback.best_val_loss_epoch\n","  best_acc_epoch = history_callback.best_acc_epoch\n","  best_f1_epoch = history_callback.best_f1_epoch\n","\n","  np.savez(os.path.join(result_path_current,'mat.npz'),\n","          elapsed_time=elapsed_time,\n","          x_test=x_test, y_test=y_test, ind_test=ind_test,\n","          epoch_list=epoch_list,\n","          train_loss=train_loss, train_acc=train_acc,\n","          val_loss=val_loss, val_acc=val_acc,\n","          pred_history=pred_history,\n","          x_other=x_other,\n","          best_val_loss_epoch=best_val_loss_epoch, best_acc_epoch=best_acc_epoch, best_f1_epoch=best_f1_epoch\n","          )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\cautious\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4], y=[0 1 0 2 0 3 0 4 1 0 3 3 1 0 0 3 0 0 0 1 0 0 2 1 1 2 4 1 3 0 0 0 1 0 0 0 1\n"," 0 0 0 4 0 0 4 0 1 1 4 0 3 1 2 0 4 1 1 1 0 0 0 0 0 3 0 0 0 0 0 1 1 1 3 1 0\n"," 0 2 2 0 0 0 2 0 0 1 0 0 4 3 2 3 2 1 0 4 1 3 3 2 2 0 0 1 1 4 0 0 0 0 2 0 0\n"," 1 0 4 1 4 1 0 0 0 0 0 0 4 3 0 0 2 4 0 0 3 3 1 1 1 0 1 4 1 0 1 1 0 0 0 3 4\n"," 0 0 1 2 0 0 4 0 0 1 2 1 0 4 1 0 2 0 0 0 2 3 3 3 2 0 4 1 1 0 0 0 0 2 0 2 0\n"," 0 3 0 0 0 2 0 2 2 0 0 0 2 1 0 0 1 2 3 0 1 1 0 3 3 2 3 3 0 0 0 1 3 4 0 1 4\n"," 0 1 2 0 2 0 0 4 3 0 0 0 0 0 0 2 3 0 0 4 0 0 2 0 0 0 0 1 4 2 2 1 0 1 1 2 1\n"," 1 2 0 1 0 1 2 2 0 3 2 4 3 3 0 3 2 0 0 4 4 4 0 2 0 3 0 4 3 0 0 0 0 0 1 0 0\n"," 0 0 0 0 0 3 3 0 0 4 1 1 4 1 3 0 4 3 0 0 1 2 2 0 0 0 2 0 4 3 3 2 0 0 2 0 1\n"," 0 3 3 0 0 2 4 3 2 0 1 0 3 1 0 1 0 4 3 0 1 2 2 0 0 2 3 0 0 4 0 1 1 0 0 0 0\n"," 2 2 0 0 1 0 0 1 2 2 0 2 2 0 2 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 4 1\n"," 4 2 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 2 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_20 (Conv2D)           (None, 160, 160, 64)      1792      \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 80, 80, 64)        0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 80, 80, 64)        0         \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 80, 80, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_21 (MaxPooling (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 40, 40, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_22 (MaxPooling (None, 20, 20, 256)       0         \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 20, 20, 256)       0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 20, 20, 512)       1180160   \n","_________________________________________________________________\n","max_pooling2d_23 (MaxPooling (None, 10, 10, 512)       0         \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 10, 10, 512)       0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 51200)             0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               13107456  \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 5)                 1285      \n","=================================================================\n","Total params: 14,659,717\n","Trainable params: 14,659,717\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1/1 [==============================] - 0s 273ms/step - loss: 1.6790 - accuracy: 0.1364 - val_loss: 2.0722 - val_accuracy: 0.1818\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\cautious\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/10\n","1/1 [==============================] - 0s 144ms/step - loss: 5.3120 - accuracy: 0.2273 - val_loss: 1.6549 - val_accuracy: 0.1136\n","Epoch 3/10\n","1/1 [==============================] - 0s 137ms/step - loss: 2.2286 - accuracy: 0.1364 - val_loss: 1.6062 - val_accuracy: 0.4773\n","Epoch 4/10\n","1/1 [==============================] - 0s 139ms/step - loss: 1.7111 - accuracy: 0.2539 - val_loss: 1.6077 - val_accuracy: 0.4773\n","Epoch 5/10\n","1/1 [==============================] - 0s 137ms/step - loss: 1.5794 - accuracy: 0.3281 - val_loss: 1.6074 - val_accuracy: 0.4773\n","Epoch 6/10\n","1/1 [==============================] - 0s 137ms/step - loss: 1.5700 - accuracy: 0.4848 - val_loss: 1.6072 - val_accuracy: 0.4773\n","Epoch 7/10\n","1/1 [==============================] - 0s 144ms/step - loss: 1.5891 - accuracy: 0.4062 - val_loss: 1.6073 - val_accuracy: 0.4773\n","Epoch 8/10\n","1/1 [==============================] - 0s 122ms/step - loss: 1.5936 - accuracy: 0.4062 - val_loss: 1.6071 - val_accuracy: 0.4773\n","Epoch 9/10\n","1/1 [==============================] - 0s 131ms/step - loss: 1.6055 - accuracy: 0.4394 - val_loss: 1.6069 - val_accuracy: 0.4773\n","Epoch 10/10\n","1/1 [==============================] - 0s 130ms/step - loss: 1.6539 - accuracy: 0.3555 - val_loss: 1.6079 - val_accuracy: 0.4773\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_24 (Conv2D)           (None, 160, 160, 64)      1792      \n","_________________________________________________________________\n","max_pooling2d_24 (MaxPooling (None, 80, 80, 64)        0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 80, 80, 64)        0         \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 80, 80, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_25 (MaxPooling (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 40, 40, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_26 (MaxPooling (None, 20, 20, 256)       0         \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 20, 20, 256)       0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 20, 20, 512)       1180160   \n","_________________________________________________________________\n","max_pooling2d_27 (MaxPooling (None, 10, 10, 512)       0         \n","_________________________________________________________________\n","dropout_33 (Dropout)         (None, 10, 10, 512)       0         \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 51200)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               13107456  \n","_________________________________________________________________\n","dropout_34 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 5)                 1285      \n","=================================================================\n","Total params: 14,659,717\n","Trainable params: 14,659,717\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1/1 [==============================] - 0s 273ms/step - loss: 1.5704 - accuracy: 0.2070 - val_loss: 2.0470 - val_accuracy: 0.1136\n","Epoch 2/10\n","1/1 [==============================] - 0s 135ms/step - loss: 7.3845 - accuracy: 0.1818 - val_loss: 1.6303 - val_accuracy: 0.0909\n","Epoch 3/10\n","1/1 [==============================] - 0s 269ms/step - loss: 2.0795 - accuracy: 0.1288 - val_loss: 1.6076 - val_accuracy: 0.1364\n","Epoch 4/10\n","1/1 [==============================] - 0s 137ms/step - loss: 1.6285 - accuracy: 0.1211 - val_loss: 1.6083 - val_accuracy: 0.1364\n","Epoch 5/10\n","1/1 [==============================] - 0s 151ms/step - loss: 1.6566 - accuracy: 0.1719 - val_loss: 1.6089 - val_accuracy: 0.1364\n","Epoch 6/10\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-21-2347f987056a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m       \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m       \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhistory_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m   )\n\u001b[0;32m     58\u001b[0m   \u001b[1;31m#print(\"elapsed : {}\".format(time.time() - start_time))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1QbRoD4XZDE","outputId":"40624949-ae50-4e01-b045-e82d918169bf"},"source":["### evaluation\n","y_true = np.argmax(y_test, axis=1)\n","y_pred = np.argmax(history_callback.best_model.predict(x_test),axis=1)\n","accuracy = metrics.accuracy_score(y_true,y_pred)\n","precision, sensitivity, fscore, support = metrics.precision_recall_fscore_support(y_true, y_pred)\n","auc1 = metrics.roc_auc_score(y_true, history_callback.best_model.predict(x_test), multi_class='ovo')\n","auc2 = metrics.roc_auc_score(y_true, history_callback.best_model.predict(x_test), multi_class='ovr')\n","conf_mat = confusion_matrix(y_true,y_pred)\n","\n","print(accuracy)\n","print(precision)\n","print(recall)\n","print(fscore)\n","print(support)\n","print(auc1)\n","print(auc2)\n","print(conf_mat)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.2\n","[0.  0.2 0.  0. ]\n","[0.80952381 0.125      0.5        1.        ]\n","[0.         0.33333333 0.         0.        ]\n","[21  8  6  5]\n","0.5352347883597883\n","0.5300862795776206\n","[[ 0 21  0  0]\n"," [ 0  8  0  0]\n"," [ 0  6  0  0]\n"," [ 0  5  0  0]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}